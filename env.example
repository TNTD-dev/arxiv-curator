# =============================================================================
# AI Research Paper Navigator - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your actual values
# Never commit the .env file to version control!

# -----------------------------------------------------------------------------
# Groq API Configuration (REQUIRED)
# -----------------------------------------------------------------------------
# Get your API key from: https://console.groq.com/keys
GROQ_API_KEY=gsk_your_groq_api_key_here

# Groq Model Selection
# Options:
#   - llama-3.3-70b-versatile (recommended for quality)
#   - llama-3.1-70b-versatile (previous version)
#   - mixtral-8x7b-32768 (good balance, large context)
#   - llama-3.1-8b-instant (fastest option)
#   - gemma2-9b-it (good for reasoning tasks)
GROQ_MODEL=llama-3.3-70b-versatile

# LLM Generation Parameters
GROQ_MAX_TOKENS=2048
GROQ_TEMPERATURE=0.1

# -----------------------------------------------------------------------------
# OpenAI API Configuration (OPTIONAL)
# -----------------------------------------------------------------------------
# Required ONLY for real RAGAS evaluation metrics (Phase 8)
# Get free $5 credit for new accounts: https://platform.openai.com/api-keys
# Leave empty to use mock evaluation scores (free)
OPENAI_API_KEY=sk_your_openai_key_here

# -----------------------------------------------------------------------------
# Langfuse Observability Configuration (OPTIONAL)
# -----------------------------------------------------------------------------
# Get your keys from: https://cloud.langfuse.com
# Leave empty to disable observability features
LANGFUSE_PUBLIC_KEY=pk_your_public_key_here
LANGFUSE_SECRET_KEY=sk_your_secret_key_here
LANGFUSE_HOST=https://cloud.langfuse.com

# -----------------------------------------------------------------------------
# arXiv Configuration
# -----------------------------------------------------------------------------
# Search query for arXiv papers
# Examples:
#   - cat:cs.AI OR cat:cs.LG (AI and Machine Learning)
#   - cat:cs.CL (Computational Linguistics / NLP)
#   - all:transformer (search for "transformer" in all fields)
ARXIV_QUERY=cat:cs.AI OR cat:cs.LG

# Maximum number of papers to fetch
ARXIV_MAX_RESULTS=10

# -----------------------------------------------------------------------------
# Embedding & Retrieval Configuration
# -----------------------------------------------------------------------------
# Sentence transformer model for embeddings
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Retrieval parameters
TOP_K_RETRIEVAL=20
TOP_K_RERANK=5

# Chunking parameters
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# -----------------------------------------------------------------------------
# Re-ranking Model
# -----------------------------------------------------------------------------
RERANK_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# -----------------------------------------------------------------------------
# BM25 Parameters
# -----------------------------------------------------------------------------
BM25_K1=1.5
BM25_B=0.75

# -----------------------------------------------------------------------------
# Qdrant Vector Database Configuration
# -----------------------------------------------------------------------------
# For Docker deployment, use service name 'qdrant'
# For local development, use 'localhost'
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=arxiv_papers
QDRANT_DISTANCE=Cosine


